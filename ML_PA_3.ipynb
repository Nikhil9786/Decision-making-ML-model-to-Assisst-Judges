{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_PA_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uczzNMC1fbuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#######################################################################################################################\n",
        "\"\"\" Groups all cases by metric, creating a dictionary with each group value as a key\n",
        "@:param test_data:      List of lists, the full data set to pull groups from\n",
        "@:param categories:     List of column titles, stored separately from the numerical data\n",
        "@:param metric:         String used to determine groups, i.e 'race'\n",
        "@:param mappings:       Dictionary mappings from training, used to convert the data between numerical and string format\n",
        "@:param predictions:    List of predicted values produced from a machine learning model.\n",
        "@:param labels:         List of labels for the test data\n",
        "\n",
        "@:note: test_data, predictions, and labels should correspond to one another\n",
        "@:note: Groups with less than 50 members are not considered sufficiently representative and are excluded. \n",
        "\n",
        "@:returns total_cases:  Dictionary with each group value as keys. Each key has a list of (prediction, label) tuples\n",
        "representing all of the data points within that group\n",
        "\"\"\"\n",
        "\n",
        "def get_cases_by_metric(test_data, categories, metric, mappings, predictions, labels):\n",
        "\n",
        "    total_cases = {}\n",
        "    index = -1\n",
        "    for i in range(len(categories)):\n",
        "        if metric in categories[i]:\n",
        "            index = i\n",
        "            break\n",
        "\n",
        "    for value in mappings[metric].keys():\n",
        "        cases = []\n",
        "        for i in range(len(test_data)):\n",
        "            if test_data[i][index] == mappings[metric][value]:\n",
        "                cases.append((float(predictions[i]), int(labels[i])))\n",
        "\n",
        "        # Only include groups that have more than 50 members\n",
        "        if len(cases) > 50:\n",
        "            total_cases[value] = cases\n",
        "\n",
        "    return total_cases\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Applies a threshold to real-valued model predictions to make them either 0 or 1. Values above the threshold become\n",
        "1's, values below or equal to the threshold become 0's.\n",
        "\n",
        "@:param predictions:    Tuples of the form (prediction, label), such as those returned by get_cases_by_metric\n",
        "@:param threshold:      Float or Int value used to calculate the predicted value\n",
        "\n",
        "@:returns predictions:  The thresholded version of the same input (prediction, label) tuples \n",
        "\"\"\"\n",
        "\n",
        "def apply_threshold(prediction_label_pairs, threshold):\n",
        "\n",
        "    threshed = [(0, 0)] * len(prediction_label_pairs)\n",
        "    for i in range(len(prediction_label_pairs)):\n",
        "        if prediction_label_pairs[i][0] <= threshold:\n",
        "            threshed[i] = (0, prediction_label_pairs[i][1])\n",
        "        else:\n",
        "            threshed[i] = (1, prediction_label_pairs[i][1])\n",
        "\n",
        "    return threshed\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Gets the total accuracy of a set of classifications\n",
        "\n",
        "@:param classifications:    a dictionary of all the classifications, separated into groups. Each group contains\n",
        "                            a list of (prediction, label) tuples\n",
        "                \n",
        "@:note:                     assumes that the predictions have been already thresholded\n",
        "\n",
        "@:returns total_accuracy:   the total accuracy of the classifications\n",
        "\"\"\"\n",
        "\n",
        "def get_total_accuracy(classifications):\n",
        "\n",
        "    total_correct = 0.0\n",
        "    total_num_cases = 0.0\n",
        "    for group in classifications.keys():\n",
        "        for prediction, label in classifications[group]:\n",
        "            total_num_cases += 1.0\n",
        "            if prediction == label:\n",
        "                total_correct += 1.0\n",
        "\n",
        "    return total_correct / total_num_cases\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of correct predictions in a group\n",
        "\n",
        "@:param prediction_label_pairs:       List of (prediction, label) tuples\n",
        "\n",
        "@:note:             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns num_correct:  Int value of correct predictions. Dividing this by len(category) would give the\n",
        "                        accuracy for the group\n",
        "\"\"\"\n",
        "\n",
        "def get_num_correct(prediction_label_pairs):\n",
        "    num_correct = 0\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if prediction == label:\n",
        "            num_correct += 1\n",
        "\n",
        "    return num_correct\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of false positives in a group\n",
        "\n",
        "@:param prediction_label_pairs:   List of (prediction, label) tuples\n",
        "\n",
        "@:note:             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns false_positives:        The number of false positives (prediction == 1, label == 0)\n",
        "\"\"\"\n",
        "def get_num_false_positives(prediction_label_pairs):\n",
        "    false_positives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if prediction == 1 and label == 0:\n",
        "            false_positives += 1\n",
        "\n",
        "    return false_positives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the rate of false positives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns FPR:                      The number of false positives divided by the number of labelled negatives. Will \n",
        "                                    return 0 to avoid divide by 0, but in practice there should be no instances of no \n",
        "                                    labelled negatives.\n",
        "\"\"\"\n",
        "\n",
        "def get_false_positive_rate(prediction_label_pairs):\n",
        "    false_positives = 0\n",
        "    labelled_negatives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if label == 0:\n",
        "            labelled_negatives += 1\n",
        "            if prediction == 1:\n",
        "                false_positives += 1\n",
        "\n",
        "    if labelled_negatives != 0:\n",
        "        return false_positives / labelled_negatives\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of true negatives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns true_negatives            The number of true negatives (prediction == 0, label == 0)\n",
        "\"\"\"\n",
        "\n",
        "def get_num_true_negatives(prediction_label_pairs):\n",
        "    true_negatives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if prediction == 0 and label == 0:\n",
        "            true_negatives += 1\n",
        "\n",
        "    return true_negatives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the rate of true negatives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns TNR:                      1 - false_positive_rate.\n",
        "\"\"\"\n",
        "\n",
        "def get_true_negative_rate(prediction_labels_pairs):\n",
        "\n",
        "    return 1 - get_false_positive_rate(prediction_labels_pairs)\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of false negatives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns false_negatives           The number of false negatives (prediction == 0, label == 1)\n",
        "\"\"\"\n",
        "\n",
        "def get_num_false_negatives(prediction_label_pairs):\n",
        "    false_negatives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if prediction == 0 and label == 1:\n",
        "            false_negatives += 1\n",
        "\n",
        "    return false_negatives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the rate of false negatives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns FNR:                      The number of false negatives divided by the number of labelled positives. Will \n",
        "                                    return 0 to avoid divide by 0, but in practice there should be no instances of no \n",
        "                                    labelled positives.\n",
        "\"\"\"\n",
        "\n",
        "def get_false_negative_rate(prediction_label_pairs):\n",
        "    false_negatives = 0\n",
        "    labelled_positives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if label == 1:\n",
        "            labelled_positives += 1\n",
        "            if prediction == 0:\n",
        "                false_negatives += 1\n",
        "\n",
        "    if labelled_positives != 0:\n",
        "        return false_negatives / labelled_positives\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of true positives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns true_positives           The number of true positives (prediction == 1, label == 1)\n",
        "\"\"\"\n",
        "\n",
        "def get_num_true_positives(prediction_label_pairs):\n",
        "    true_positives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        label = int(pair[1])\n",
        "        if prediction == 1 and label == 1:\n",
        "            true_positives += 1\n",
        "\n",
        "    return true_positives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the rate of true positives in a group\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns TPR:                      1 - false_negative_rate.\n",
        "\"\"\"\n",
        "\n",
        "def get_true_positive_rate(category):\n",
        "\n",
        "    return 1 - get_false_negative_rate(category)\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the number of samples that have a positive prediction\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns predicted_positives       Number of samples with a positive prediction\"\"\"\n",
        "\n",
        "def get_num_predicted_positives(prediction_label_pairs):\n",
        "    predicted_positives = 0\n",
        "\n",
        "    for pair in prediction_label_pairs:\n",
        "        prediction = int(pair[0])\n",
        "        if prediction == 1:\n",
        "            predicted_positives += 1\n",
        "\n",
        "    return predicted_positives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Determines the positive predictive value of a group, defined as the number of true positives divided by the \n",
        "number of predicted positives\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns PPV:                      true positives / predicted positives                          \n",
        "\"\"\"\n",
        "\n",
        "def get_positive_predictive_value(prediction_label_pairs):\n",
        "    true_positives = get_num_true_positives(prediction_label_pairs)\n",
        "    predicted_positives = get_num_predicted_positives(prediction_label_pairs)\n",
        "\n",
        "    if predicted_positives == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return true_positives / predicted_positives\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\"Calculates the Fscore (or harmonic mean) of a group. Used as a substitute for accuracy when data is skewed\n",
        "\n",
        "@:param prediction_label_pairs:     List of (prediction, label) tuples\n",
        "\n",
        "@:note:                             Assumes predictions have already been thresholded\n",
        "\n",
        "@:returns Fscore                    Harmonic mean, defined as 2 * (precision * recall) + (precision + recall)\n",
        "\"\"\"\n",
        "\n",
        "def calculate_Fscore(prediction_label_pairs):\n",
        "\n",
        "    precision = get_positive_predictive_value(prediction_label_pairs)\n",
        "    recall = get_true_positive_rate(prediction_label_pairs)\n",
        "\n",
        "    numerator = precision * recall\n",
        "    denominator = precision + recall\n",
        "\n",
        "    return 2 * (numerator/denominator)\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def get_ROC_data(prediction_label_pairs, group):\n",
        "    true_positives = []\n",
        "    false_positives = []\n",
        "    for i in range(1, 101):\n",
        "        threshold = float(i) / 100.0\n",
        "        eval_copy = list.copy(prediction_label_pairs)\n",
        "        eval_copy = apply_threshold(eval_copy, threshold)\n",
        "        TPR = get_true_positive_rate(eval_copy)\n",
        "        FPR = get_false_positive_rate(eval_copy)\n",
        "        true_positives.append(TPR)\n",
        "        false_positives.append(FPR)\n",
        "\n",
        "    return (true_positives, false_positives, group)\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def plot_ROC_data(ROC_data_list):\n",
        "    for curve in  ROC_data_list:\n",
        "        TPR = curve[0]\n",
        "        FPR = curve[1]\n",
        "        title = curve[2]\n",
        "        plt.plot(FPR, TPR, label=title)\n",
        "\n",
        "    plt.legend()\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([0.0, 1.0])\n",
        "    axes.set_ylim([0.0, 1.0])\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def apply_financials(data, group_level=False):\n",
        "\n",
        "    # Costs for the various categories\n",
        "    tp_val = -60076\n",
        "    tn_val = 23088\n",
        "    fp_val = -110076\n",
        "    fn_val = -202330\n",
        "\n",
        "    full_list = []\n",
        "    if group_level:\n",
        "        full_list = data\n",
        "    else:\n",
        "        for group in data.keys():\n",
        "            full_list += data[group]\n",
        "\n",
        "    num_tp = get_num_true_positives(full_list)\n",
        "    num_tn = get_num_true_negatives(full_list)\n",
        "    num_fp = get_num_false_positives(full_list)\n",
        "    num_fn = get_num_false_negatives(full_list)\n",
        "\n",
        "    total = 0.0\n",
        "    total += num_tp * tp_val\n",
        "    total += num_tn * tn_val\n",
        "    total += num_fp * fp_val\n",
        "    total += num_fn * fn_val\n",
        "\n",
        "    return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgGWlxNgfhNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from utils import *\n",
        "#######################################################################################################################\n",
        "# YOU MUST FILL OUT YOUR SECONDARY OPTIMIZATION METRIC (either accuracy or cost)!\n",
        "# The metric chosen must be the same for all 5 methods.\n",
        "#\n",
        "# Chosen Secondary Optimization Metric: #\n",
        "#######################################################################################################################\n",
        "\"\"\" Determines the thresholds such that each group has equal predictive positive rates within \n",
        "    a tolerance value epsilon. For the Naive Bayes Classifier and SVM you should be able to find\n",
        "    a nontrivial solution with epsilon=0.02. \n",
        "    Chooses the best solution of those that satisfy this constraint based on chosen \n",
        "    secondary optimization criteria.\n",
        "\"\"\"\n",
        "def enforce_demographic_parity(categorical_results, epsilon):\n",
        "    demographic_parity_data = {}\n",
        "    test_data = {}\n",
        "    thresholds = {'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Other': 0}\n",
        "    accuracy = 0\n",
        "\n",
        "    thresh_list = []\n",
        "    afr_pred_pos, cauc_pred_pos, hisp_pred_pos, oth_pred_pos = [],[],[],[]\n",
        "    test_thresholds = []\n",
        "    # Must complete this function!\n",
        "    #return demographic_parity_data, thresholds\n",
        "    for i in [float(j) / 100 for j in range(0, 100, 1)]:\n",
        "        thresh_list.append(i)\n",
        "        \n",
        "        test_data['African-American'] = apply_threshold(categorical_results['African-American'], i)\n",
        "        afr_pred_pos.append(get_num_predicted_positives(test_data['African-American'])/len(test_data['African-American']))\n",
        "\n",
        "        test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], i)\n",
        "        cauc_pred_pos.append(get_num_predicted_positives(test_data['Caucasian'])/len(test_data['Caucasian']))\n",
        "\n",
        "        test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], i)\n",
        "        hisp_pred_pos.append(get_num_predicted_positives(test_data['Hispanic'])/len(test_data['Hispanic']))\n",
        "\n",
        "        test_data['Other'] = apply_threshold(categorical_results['Other'], i)\n",
        "        oth_pred_pos.append(get_num_predicted_positives(test_data['Other'])/len(test_data['Other']))\n",
        "     \n",
        "    for afr_prob in afr_pred_pos:\n",
        "        for cauc_prob in cauc_pred_pos:\n",
        "            if compare_probs(cauc_prob,afr_prob,epsilon) == False:\n",
        "                continue\n",
        "            for hisp_prob in hisp_pred_pos:\n",
        "                if compare_probs(hisp_prob,afr_prob,epsilon) == False or compare_probs(hisp_prob,cauc_prob,epsilon) == False:\n",
        "                       continue\n",
        "                for oth_prob in oth_pred_pos:\n",
        "                    if compare_probs(oth_prob,afr_prob,epsilon) == False or compare_probs(oth_prob,cauc_prob,epsilon) == False or compare_probs(oth_prob,hisp_prob,epsilon) == False:\n",
        "                            continue\n",
        "                    else:\n",
        "                        poss_threshold = [thresh_list[afr_pred_pos.index(afr_prob)], thresh_list[cauc_pred_pos.index(cauc_prob)], thresh_list[hisp_pred_pos.index(hisp_prob)], thresh_list[oth_pred_pos.index(oth_prob)]]\n",
        "                        if poss_threshold not in test_thresholds:\n",
        "                            test_thresholds.append(poss_threshold)\n",
        "      \n",
        "    for thresh in test_thresholds:\n",
        "        test_data['African-American'] = apply_threshold(categorical_results['African-American'], thresh[0])\n",
        "        test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], thresh[1])\n",
        "        test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], thresh[2])\n",
        "        test_data['Other'] = apply_threshold(categorical_results['Other'], thresh[3])\n",
        "        total_accuracy = get_total_accuracy(test_data)\n",
        "        if total_accuracy > accuracy:\n",
        "            accuracy = total_accuracy\n",
        "            thresholds = {'African-American': thresh[0], 'Caucasian': thresh[1], 'Hispanic': thresh[2], 'Other': thresh[3]}\n",
        "\n",
        "    # return final solution                 \n",
        "    for key in categorical_results.keys():\n",
        "        threshold = thresholds[key]\n",
        "        demographic_parity_data[key] = apply_threshold(categorical_results[key], threshold)\n",
        "    return demographic_parity_data, thresholds\n",
        "                        \n",
        "                                    \n",
        "#     return None, None\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\" Determine thresholds such that all groups have equal TPR within some tolerance value epsilon, \n",
        "    and chooses best solution according to chosen secondary optimization criteria. For the Naive \n",
        "    Bayes Classifier and SVM you should be able to find a non-trivial solution with epsilon=0.01\n",
        "\"\"\"\n",
        "def enforce_equal_opportunity(categorical_results, epsilon):\n",
        "    test_data, equal_opportunity_data = {}, {}\n",
        "    thresholds = {'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Other': 0}\n",
        "    accuracy = 0\n",
        "\n",
        "    thresh_list = []\n",
        "    afr_tpr, cauc_tpr, hisp_tpr, oth_tpr = [],[],[],[]\n",
        "    test_thresholds = []\n",
        "    \n",
        "    for i in [float(j) / 100 for j in range(0, 100, 1)]:\n",
        "        thresh_list.append(i)\n",
        "        \n",
        "        test_data['African-American'] = apply_threshold(categorical_results['African-American'], i)\n",
        "        afr_tpr.append(get_true_positive_rate(test_data['African-American']))\n",
        "\n",
        "        test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], i)\n",
        "        cauc_tpr.append(get_true_positive_rate(test_data['Caucasian']))\n",
        "\n",
        "        test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], i)\n",
        "        hisp_tpr.append(get_true_positive_rate(test_data['Hispanic']))\n",
        "\n",
        "        test_data['Other'] = apply_threshold(categorical_results['Other'], i)\n",
        "        oth_tpr.append(get_true_positive_rate(test_data['Other']))\n",
        "     \n",
        "    for afr_prob in afr_tpr:\n",
        "        for cauc_prob in cauc_tpr:\n",
        "            if compare_probs(cauc_prob,afr_prob,epsilon) == False:\n",
        "                continue\n",
        "            for hisp_prob in hisp_tpr:\n",
        "                if compare_probs(hisp_prob,afr_prob,epsilon) == False or compare_probs(hisp_prob,cauc_prob,epsilon) == False:\n",
        "                       continue\n",
        "                for oth_prob in oth_tpr:\n",
        "                    if compare_probs(oth_prob,afr_prob,epsilon) == False or compare_probs(oth_prob,cauc_prob,epsilon) == False or compare_probs(oth_prob,hisp_prob,epsilon) == False:\n",
        "                            continue\n",
        "                    else:\n",
        "                        poss_threshold = [thresh_list[afr_tpr.index(afr_prob)], thresh_list[cauc_tpr.index(cauc_prob)], thresh_list[hisp_tpr.index(hisp_prob)], thresh_list[oth_tpr.index(oth_prob)]]\n",
        "                        if poss_threshold not in test_thresholds:\n",
        "                            test_thresholds.append(poss_threshold)\n",
        "      \n",
        "    for thresh in test_thresholds:\n",
        "        test_data['African-American'] = apply_threshold(categorical_results['African-American'], thresh[0])\n",
        "        test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], thresh[1])\n",
        "        test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], thresh[2])\n",
        "        test_data['Other'] = apply_threshold(categorical_results['Other'], thresh[3])\n",
        "        total_accuracy = get_total_accuracy(test_data)\n",
        "        if total_accuracy > accuracy:\n",
        "            accuracy = total_accuracy\n",
        "            thresholds = {'African-American': thresh[0], 'Caucasian': thresh[1], 'Hispanic': thresh[2], 'Other': thresh[3]}\n",
        "\n",
        "    # return final solution                 \n",
        "    for key in categorical_results.keys():\n",
        "        threshold = thresholds[key]\n",
        "        equal_opportunity_data[key] = apply_threshold(categorical_results[key], threshold)\n",
        "    return equal_opportunity_data, thresholds\n",
        "\n",
        "    # Must complete this function!\n",
        "    #return equal_opportunity_data, thresholds\n",
        "\n",
        "#     return None, None\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "\"\"\"Determines which thresholds to use to achieve the maximum profit or maximum accuracy with the given data\n",
        "\"\"\"\n",
        "\n",
        "def enforce_maximum_profit(categorical_results):\n",
        "    test_data, mp_data = {}, {}\n",
        "    thresholds = {}\n",
        "    \n",
        "    afr_max, cauc_max, hisp_max, oth_max = 0,0,0,0\n",
        "    for i in [float(j) / 100 for j in range(0, 100, 1)]:\n",
        "        test_data['African-American'] = apply_threshold(categorical_results['African-American'], i)\n",
        "        afr_acc = get_num_correct(test_data['African-American'])/len(test_data['African-American'])\n",
        "        if afr_acc > afr_max:\n",
        "            afr_max = afr_acc\n",
        "            thresholds['African-American'] = i\n",
        "        \n",
        "        test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], i)\n",
        "        cauc_acc = get_num_correct(test_data['Caucasian'])/len(test_data['Caucasian'])\n",
        "        if cauc_acc > cauc_max:\n",
        "            cauc_max = cauc_acc\n",
        "            thresholds['Caucasian'] = i \n",
        "            \n",
        "        test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], i)\n",
        "        hisp_acc = get_num_correct(test_data['Hispanic'])/len(test_data['Hispanic'])\n",
        "        if hisp_acc > hisp_max:\n",
        "            hisp_max = hisp_acc\n",
        "            thresholds['Hispanic'] = i\n",
        "        \n",
        "        test_data['Other'] = apply_threshold(categorical_results['Other'], i)\n",
        "        oth_acc = get_num_correct(test_data['Other'])/len(test_data['Other'])\n",
        "        if oth_acc > oth_max:\n",
        "            oth_max = oth_acc\n",
        "            thresholds['Other'] = i\n",
        "       \n",
        "    for key in categorical_results.keys():\n",
        "        threshold = thresholds[key]\n",
        "        mp_data[key] = apply_threshold(categorical_results[key], threshold)\n",
        "    return mp_data, thresholds\n",
        "#     return None, None\n",
        "\n",
        "#######################################################################################################################\n",
        "\"\"\" Determine thresholds such that all groups have the same PPV, and return the best solution\n",
        "    according to chosen secondary optimization criteria\n",
        "\"\"\"\n",
        "\n",
        "def enforce_predictive_parity(categorical_results, epsilon):\n",
        "  test_data, predictive_parity_data = {},{}\n",
        "  thresholds = {'African-American': 0, 'Caucasian': 0, 'Hispanic': 0, 'Other': 0}\n",
        "  accuracy = 0\n",
        "\n",
        "  thresh_list = []\n",
        "  afr_ppv, cauc_ppv, hisp_ppv, oth_ppv = [],[],[],[]\n",
        "  test_thresholds = []\n",
        "  \n",
        "  for i in [float(j) / 100 for j in range(0, 100, 1)]:\n",
        "      thresh_list.append(i)\n",
        "      \n",
        "      test_data['African-American'] = apply_threshold(categorical_results['African-American'], i)\n",
        "      afr_ppv.append(get_positive_predictive_value(test_data['African-American']))\n",
        "\n",
        "      test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], i)\n",
        "      cauc_ppv.append(get_positive_predictive_value(test_data['Caucasian']))\n",
        "\n",
        "      test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], i)\n",
        "      hisp_ppv.append(get_positive_predictive_value(test_data['Hispanic']))\n",
        "\n",
        "      test_data['Other'] = apply_threshold(categorical_results['Other'], i)\n",
        "      oth_ppv.append(get_positive_predictive_value(test_data['Other']))\n",
        "      \n",
        "      \n",
        "  for afr_prob in afr_ppv:\n",
        "      for cauc_prob in cauc_ppv:\n",
        "          if compare_probs(cauc_prob,afr_prob,epsilon) == False:\n",
        "              continue\n",
        "          for hisp_prob in hisp_ppv:\n",
        "              if compare_probs(hisp_prob,afr_prob,epsilon) == False or compare_probs(hisp_prob,cauc_prob,epsilon) == False:\n",
        "                      continue\n",
        "              for oth_prob in oth_ppv:\n",
        "                  if compare_probs(oth_prob,afr_prob,epsilon) == False or compare_probs(oth_prob,cauc_prob,epsilon) == False or compare_probs(oth_prob,hisp_prob,epsilon) == False:\n",
        "                          continue\n",
        "                  else:\n",
        "                      poss_threshold = [thresh_list[afr_ppv.index(afr_prob)], thresh_list[cauc_ppv.index(cauc_prob)], thresh_list[hisp_ppv.index(hisp_prob)], thresh_list[oth_ppv.index(oth_prob)]]\n",
        "                      if poss_threshold not in test_thresholds:\n",
        "                          test_thresholds.append(poss_threshold)\n",
        "    \n",
        "  for thresh in test_thresholds:\n",
        "      test_data['African-American'] = apply_threshold(categorical_results['African-American'], thresh[0])\n",
        "      test_data['Caucasian'] = apply_threshold(categorical_results['Caucasian'], thresh[1])\n",
        "      test_data['Hispanic'] = apply_threshold(categorical_results['Hispanic'], thresh[2])\n",
        "      test_data['Other'] = apply_threshold(categorical_results['Other'], thresh[3])\n",
        "      total_accuracy = get_total_accuracy(test_data)\n",
        "      if total_accuracy > accuracy:\n",
        "          accuracy = total_accuracy\n",
        "          thresholds = {'African-American': thresh[0], 'Caucasian': thresh[1], 'Hispanic': thresh[2], 'Other': thresh[3]}\n",
        "\n",
        "  # return final solution                 \n",
        "  for key in categorical_results.keys():\n",
        "      threshold = thresholds[key]\n",
        "      predictive_parity_data[key] = apply_threshold(categorical_results[key], threshold)\n",
        "  return predictive_parity_data, thresholds\n",
        "#     return None, None\n",
        "\n",
        "    ###################################################################################################################\n",
        "\"\"\" Apply a single threshold to all groups, and return the best solution according to \n",
        "    chosen secondary optimization criteria\n",
        "\"\"\"\n",
        "\n",
        "def enforce_single_threshold(categorical_results):\n",
        "    test_data = {}\n",
        "    accuracy = 0\n",
        "\n",
        "    for i in [float(j) / 100 for j in range(0, 100, 1)]:\n",
        "        for key in categorical_results.keys():\n",
        "            test_data[key] = apply_threshold(categorical_results[key], i)\n",
        "        total_accuracy = get_total_accuracy(test_data)\n",
        "        if total_accuracy > accuracy:\n",
        "            accuracy = total_accuracy\n",
        "            thresholds = {'African-American': i, 'Caucasian': i, 'Hispanic': i, 'Other': i}\n",
        "\n",
        "    single_threshold_data = {}\n",
        "    for key in categorical_results.keys():\n",
        "        threshold = thresholds[key]\n",
        "        single_threshold_data[key] = apply_threshold(categorical_results[key], threshold)\n",
        "\n",
        "    return single_threshold_data, thresholds\n",
        "\n",
        "#     return None, None\n",
        "\n",
        "def compare_probs(p1, p2, epsilon):\n",
        "    return abs(p1 - p2) <= epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2VdTO40gB3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from Postprocessing import *\n",
        "# from utils import *\n",
        "from datetime import datetime\n",
        "import copy\n",
        "\n",
        "def report_results(data):\n",
        "\n",
        "    begin = datetime.now()\n",
        "\n",
        "    print(\"Attempting to enforce demographic parity...\")\n",
        "    demographic_parity_data, demographic_parity_thresholds = enforce_demographic_parity(copy.deepcopy(data), 0.02)\n",
        "    if demographic_parity_data is not None:\n",
        "\n",
        "        print(\"--------------------DEMOGRAPHIC PARITY RESULTS--------------------\")\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            num_positive_predictions = get_num_predicted_positives(demographic_parity_data[group])\n",
        "            prob = num_positive_predictions / len(demographic_parity_data[group])\n",
        "            print(\"Probability of positive prediction for \" + str(group) + \": \" + str(prob))\n",
        "\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            accuracy = get_num_correct(demographic_parity_data[group]) / len(demographic_parity_data[group])\n",
        "            print(\"Accuracy for \" + group + \": \" + str(accuracy))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            FPR = get_false_positive_rate(demographic_parity_data[group])\n",
        "            print(\"FPR for \" + group + \": \" + str(FPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            FNR = get_false_negative_rate(demographic_parity_data[group])\n",
        "            print(\"FNR for \" + group + \": \" + str(FNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            TPR = get_true_positive_rate(demographic_parity_data[group])\n",
        "            print(\"TPR for \" + group + \": \" + str(TPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_data.keys():\n",
        "            TNR = get_true_negative_rate(demographic_parity_data[group])\n",
        "            print(\"TNR for \" + group + \": \" + str(TNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in demographic_parity_thresholds.keys():\n",
        "            print(\"Threshold for \" + group + \": \" + str(demographic_parity_thresholds[group]))\n",
        "\n",
        "        print(\"\")\n",
        "        total_cost = apply_financials(demographic_parity_data)\n",
        "        print(\"Total cost: \")\n",
        "        print('${:,.0f}'.format(total_cost))\n",
        "        total_accuracy = get_total_accuracy(demographic_parity_data)\n",
        "        print(\"Total accuracy: \" + str(total_accuracy))\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "    print(\"Attempting to enforce equal opportunity...\")\n",
        "    equal_opportunity_data, equal_opportunity_thresholds = enforce_equal_opportunity(copy.deepcopy(data), 0.01)\n",
        "    if equal_opportunity_data is not None:\n",
        "        print(\"--------------------EQUAL OPPORTUNITY RESULTS--------------------\")\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_data.keys():\n",
        "            accuracy = get_num_correct(equal_opportunity_data[group]) / len(equal_opportunity_data[group])\n",
        "            print(\"Accuracy for \" + group + \": \" + str(accuracy))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_data.keys():\n",
        "            FPR = get_false_positive_rate(equal_opportunity_data[group])\n",
        "            print(\"FPR for \" + group + \": \" + str(FPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_data.keys():\n",
        "            FNR = get_false_negative_rate(equal_opportunity_data[group])\n",
        "            print(\"FNR for \" + group + \": \" + str(FNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_data.keys():\n",
        "            TPR = get_true_positive_rate(equal_opportunity_data[group])\n",
        "            print(\"TPR for \" + group + \": \" + str(TPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_data.keys():\n",
        "            TNR = get_true_negative_rate(equal_opportunity_data[group])\n",
        "            print(\"TNR for \" + group + \": \" + str(TNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in equal_opportunity_thresholds.keys():\n",
        "            print(\"Threshold for \" + group + \": \" + str(equal_opportunity_thresholds[group]))\n",
        "\n",
        "        print(\"\")\n",
        "        total_cost = apply_financials(equal_opportunity_data)\n",
        "        print(\"Total cost: \")\n",
        "        print('${:,.0f}'.format(total_cost))\n",
        "        total_accuracy = get_total_accuracy(equal_opportunity_data)\n",
        "        print(\"Total accuracy: \" + str(total_accuracy))\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "    print(\"Attempting to enforce maximum profit...\")\n",
        "    max_profit_data, max_profit_thresholds = enforce_maximum_profit(copy.deepcopy(data))\n",
        "    if max_profit_data is not None:\n",
        "        print(\"--------------------MAXIMUM PROFIT RESULTS--------------------\")\n",
        "        print(\"\")\n",
        "        for group in max_profit_data.keys():\n",
        "            accuracy = get_num_correct(max_profit_data[group]) / len(max_profit_data[group])\n",
        "            print(\"Accuracy for \" + group + \": \" + str(accuracy))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in max_profit_data.keys():\n",
        "            FPR = get_false_positive_rate(max_profit_data[group])\n",
        "            print(\"FPR for \" + group + \": \" + str(FPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in max_profit_data.keys():\n",
        "            FNR = get_false_negative_rate(max_profit_data[group])\n",
        "            print(\"FNR for \" + group + \": \" + str(FNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in max_profit_data.keys():\n",
        "            TPR = get_true_positive_rate(max_profit_data[group])\n",
        "            print(\"TPR for \" + group + \": \" + str(TPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in max_profit_data.keys():\n",
        "            TNR = get_true_negative_rate(max_profit_data[group])\n",
        "            print(\"TNR for \" + group + \": \" + str(TNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in max_profit_thresholds.keys():\n",
        "            print(\"Threshold for \" + group + \": \" + str(max_profit_thresholds[group]))\n",
        "\n",
        "        print(\"\")\n",
        "        total_cost = apply_financials(max_profit_data)\n",
        "        print(\"Total cost: \")\n",
        "        print('${:,.0f}'.format(total_cost))\n",
        "        total_accuracy = get_total_accuracy(max_profit_data)\n",
        "        print(\"Total accuracy: \" + str(total_accuracy))\n",
        "\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "    print(\"Attempting to enforce predictive parity...\")\n",
        "    predictive_parity_data, predictive_parity_thresholds = enforce_predictive_parity(copy.deepcopy(data), 0.01)\n",
        "    if predictive_parity_data is not None:\n",
        "        print(\"--------------------PREDICTIVE PARITY RESULTS--------------------\")\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            accuracy = get_num_correct(predictive_parity_data[group]) / len(predictive_parity_data[group])\n",
        "            print(\"Accuracy for \" + group + \": \" + str(accuracy))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            PPV = get_positive_predictive_value(predictive_parity_data[group])\n",
        "            print(\"PPV for \" + group + \": \" + str(PPV))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            FPR = get_false_positive_rate(predictive_parity_data[group])\n",
        "            print(\"FPR for \" + group + \": \" + str(FPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            FNR = get_false_negative_rate(predictive_parity_data[group])\n",
        "            print(\"FNR for \" + group + \": \" + str(FNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            TPR = get_true_positive_rate(predictive_parity_data[group])\n",
        "            print(\"TPR for \" + group + \": \" + str(TPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_data.keys():\n",
        "            TNR = get_true_negative_rate(predictive_parity_data[group])\n",
        "            print(\"TNR for \" + group + \": \" + str(TNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in predictive_parity_thresholds.keys():\n",
        "            print(\"Threshold for \" + group + \": \" + str(predictive_parity_thresholds[group]))\n",
        "\n",
        "        print(\"\")\n",
        "        total_cost = apply_financials(predictive_parity_data)\n",
        "        print(\"Total cost: \")\n",
        "        print('${:,.0f}'.format(total_cost))\n",
        "        total_accuracy = get_total_accuracy(predictive_parity_data)\n",
        "        print(\"Total accuracy: \" + str(total_accuracy))\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        print(\"\")\n",
        "\n",
        "    print(\"Attempting to enforce single threshold...\")\n",
        "    single_threshold_data, single_thresholds = enforce_single_threshold(copy.deepcopy(data))\n",
        "    if single_threshold_data is not None:\n",
        "        print(\"--------------------SINGLE THRESHOLD RESULTS--------------------\")\n",
        "        print(\"\")\n",
        "        for group in single_threshold_data.keys():\n",
        "            accuracy = get_num_correct(single_threshold_data[group]) / len(single_threshold_data[group])\n",
        "            print(\"Accuracy for \" + group + \": \" + str(accuracy))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in single_threshold_data.keys():\n",
        "            FPR = get_false_positive_rate(single_threshold_data[group])\n",
        "            print(\"FPR for \" + group + \": \" + str(FPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in single_threshold_data.keys():\n",
        "            FNR = get_false_negative_rate(single_threshold_data[group])\n",
        "            print(\"FNR for \" + group + \": \" + str(FNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in single_threshold_data.keys():\n",
        "            TPR = get_true_positive_rate(single_threshold_data[group])\n",
        "            print(\"TPR for \" + group + \": \" + str(TPR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in single_threshold_data.keys():\n",
        "            TNR = get_true_negative_rate(single_threshold_data[group])\n",
        "            print(\"TNR for \" + group + \": \" + str(TNR))\n",
        "\n",
        "        print(\"\")\n",
        "        for group in single_thresholds.keys():\n",
        "            print(\"Threshold for \" + group + \": \" + str(single_thresholds[group]))\n",
        "\n",
        "        print(\"\")\n",
        "        total_cost = apply_financials(single_threshold_data)\n",
        "        print(\"Total cost: \")\n",
        "        print('${:,.0f}'.format(total_cost))\n",
        "        total_accuracy = get_total_accuracy(single_threshold_data)\n",
        "        print(\"Total accuracy: \" + str(total_accuracy))\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "\n",
        "        end = datetime.now()\n",
        "\n",
        "        seconds = end-begin\n",
        "        print(\"Postprocessing took approximately: \" + str(seconds) + \" seconds\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP0XhkCVgHIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import random\n",
        "\n",
        "def preprocess(metrics, recalculate=False, causal=False):\n",
        "\n",
        "    categories, data = clean_data()\n",
        "    if recalculate:\n",
        "        training_data, training_labels, test_data, test_labels = split_data(data, categories, 0.2, causal=causal)\n",
        "        print(\"Recalculating data...\")\n",
        "    else:\n",
        "        try:\n",
        "            training_data = np.load(\"COMPAS_train_data.npy\")\n",
        "            training_labels = np.load(\"COMPAS_train_labels.npy\")\n",
        "            test_data = np.load(\"COMPAS_test_data.npy\")\n",
        "            test_labels = np.load(\"COMPAS_test_labels.npy\")\n",
        "            for i in range(len(training_labels)):\n",
        "                training_labels[i] = int(training_labels[i])\n",
        "            for i in range(len(test_labels)):\n",
        "                test_labels[i] = int(test_labels[i])\n",
        "            data = np.concatenate((training_data, test_data))\n",
        "            print(\"Loaded training data\")\n",
        "\n",
        "        except:\n",
        "            training_data, training_labels, test_data, test_labels = split_data(data, categories, 0.2, causal=causal)\n",
        "            print(\"Could not locate data...\")\n",
        "\n",
        "    used_metrics = metrics\n",
        "    training_data, reduced_categories, training_predictions = reduce_data(categories, training_data, used_metrics)\n",
        "    np.save(\"COMPAS_train_decile_scores\", training_predictions)\n",
        "    test_data, reduced_categories, test_predictions = reduce_data(categories, test_data, used_metrics)\n",
        "    np.save(\"COMPAS_test_decile_scores\", test_predictions)\n",
        "    mappings = determine_mappings(data, used_metrics)\n",
        "    vectorize_data(training_data, reduced_categories, metrics, mappings)\n",
        "    vectorize_data(test_data, reduced_categories, metrics, mappings)\n",
        "    vectorize_labels(training_labels)\n",
        "    vectorize_labels(test_labels)\n",
        "\n",
        "    training_data = np.array(training_data)\n",
        "    test_data = np.array(test_data)\n",
        "    training_labels = np.array(training_labels)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    return training_data, training_labels, test_data, test_labels, reduced_categories, mappings\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def metric_vs_recid(metric):\n",
        "    with open(\"compas-scores-two-years.csv\", \"r+\") as compas_data:\n",
        "        #print(\"Opened data file\")\n",
        "        reader = csv.reader(compas_data)\n",
        "        totals = {}\n",
        "        possible_values = {}\n",
        "        is_recid = 52\n",
        "        index = -1\n",
        "        categories = reader.__next__()\n",
        "        for i in range(len(categories)):\n",
        "            if metric in categories[i]:\n",
        "                index = i\n",
        "\n",
        "        if index == -1:\n",
        "            print(\"Couldn't find metric: \" + metric)\n",
        "            return\n",
        "\n",
        "        row = reader.__next__()\n",
        "        while row is not None:\n",
        "\n",
        "            if row[is_recid] != \"-1\":\n",
        "                if row[index] in possible_values:\n",
        "                    possible_values[row[index]] = int(possible_values[row[index]]) + int(row[is_recid])\n",
        "                    totals[row[index]] = int(totals[row[index]]) + 1\n",
        "                else:\n",
        "                    possible_values[row[index]] = row[is_recid]\n",
        "                    totals[row[index]] = 1\n",
        "\n",
        "            try:\n",
        "                row = reader.__next__()\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        for value in possible_values:\n",
        "            print(str(value) + \": \" + str(int(possible_values[value])*100/int(totals[value])))\n",
        "        print(\"\")\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def clean_data():\n",
        "    pos_data = []\n",
        "    neg_data = []\n",
        "    # Reads data from csv into a list of lists\n",
        "    # Throws out any rows with a -1 for recidivism\n",
        "    with open(\"compas-scores-two-years.csv\", \"r+\") as compas_data:\n",
        "        is_recid = 52\n",
        "        #print(\"Opened data file\")\n",
        "        reader = csv.reader(compas_data)\n",
        "        categories = reader.__next__()\n",
        "        row = reader.__next__()\n",
        "        while True:\n",
        "\n",
        "            if row[is_recid] != \"-1\":\n",
        "                if row[is_recid] == \"0\":\n",
        "                    neg_data.append(row)\n",
        "                else:\n",
        "                    pos_data.append(row)\n",
        "\n",
        "            try:\n",
        "                row = reader.__next__()\n",
        "            except:\n",
        "                break\n",
        "\n",
        "        if len(pos_data) < len(neg_data):\n",
        "            data = pos_data + random.sample(neg_data, len(pos_data))\n",
        "        else:\n",
        "            data = neg_data + random.sample(pos_data, len(neg_data))\n",
        "\n",
        "    random.shuffle(data)\n",
        "\n",
        "    return categories, data\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def split_data(data, categories, percent_test, causal=False):\n",
        "\n",
        "    if causal:\n",
        "        data = enforce_causal_discrimination(data, categories, \"race\", \"Caucasian\")\n",
        "\n",
        "    is_recid = 52\n",
        "\n",
        "    sample_size = int(percent_test * len(data))\n",
        "\n",
        "    while True:\n",
        "        training_data = data[:-sample_size]\n",
        "        test_data = data[-sample_size:]\n",
        "\n",
        "        training_labels = []\n",
        "        test_labels = []\n",
        "\n",
        "        for i in range(len(training_data)):\n",
        "            training_labels.append(training_data[i][is_recid])\n",
        "\n",
        "        zeros = 0\n",
        "        ones = 0\n",
        "        for i in range(len(test_data)):\n",
        "            if test_data[i][is_recid] == \"0\":\n",
        "                zeros += 1\n",
        "            else:\n",
        "                ones += 1\n",
        "            test_labels.append(test_data[i][is_recid])\n",
        "\n",
        "        if zeros == ones:\n",
        "            break\n",
        "        else:\n",
        "            random.shuffle(data)\n",
        "\n",
        "    np.save(\"COMPAS_train_data\", training_data)\n",
        "    np.save(\"COMPAS_train_labels\", training_labels)\n",
        "    np.save(\"COMPAS_test_data\", test_data)\n",
        "    np.save(\"COMPAS_test_labels\", test_labels)\n",
        "    return training_data, training_labels, test_data, test_labels\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def vectorize_data(data, categories, metrics, mappings):\n",
        "\n",
        "    for metric in metrics:\n",
        "        index = -1\n",
        "        for i in range(len(categories)):\n",
        "            if metric in categories[i]:\n",
        "                index = i\n",
        "                break\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            data[i][index] = mappings[metric][data[i][index]]\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def vectorize_labels(labels):\n",
        "    for i in range(len(labels)):\n",
        "        labels[i] = int(labels[i])\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def reduce_data(categories, data, keep_metrics):\n",
        "    metric_indices = []\n",
        "    reduced_categories = []\n",
        "    for metric in keep_metrics:\n",
        "        metric_indices.append(categories.index(metric))\n",
        "\n",
        "    prediction_index = -1\n",
        "    for i in range(len(categories)):\n",
        "        if \"decile_score\" in categories[i]:\n",
        "            prediction_index = i\n",
        "    predictions = []\n",
        "\n",
        "    reduced_data = []\n",
        "    for i in range(len(data)):\n",
        "        row = []\n",
        "        for index in metric_indices:\n",
        "            row.append(data[i][index])\n",
        "        reduced_data.append(row)\n",
        "        predictions.append(data[i][prediction_index])\n",
        "\n",
        "    for index in metric_indices:\n",
        "        reduced_categories.append(categories[index])\n",
        "\n",
        "    return reduced_data, reduced_categories, predictions\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def determine_mappings(data, keep_metrics):\n",
        "\n",
        "    with open(\"compas-scores-two-years.csv\", \"r+\") as compas_data:\n",
        "        #print(\"Opened data file\")\n",
        "        mappings = {}\n",
        "        reader = csv.reader(compas_data)\n",
        "        index = -1\n",
        "        categories = reader.__next__()\n",
        "        for metric in keep_metrics:\n",
        "            mappings[metric] = {}\n",
        "            for i in range(len(categories)):\n",
        "                if metric in categories[i]:\n",
        "                    index = i\n",
        "                    break\n",
        "\n",
        "            if index == -1:\n",
        "                print(\"Couldn't find metric: \" + metric)\n",
        "                return\n",
        "\n",
        "            possible_values = set()\n",
        "            for i in range(len(data)):\n",
        "                possible_values.add(data[i][index])\n",
        "\n",
        "            for i, value in enumerate(sorted(possible_values)):\n",
        "                mappings[metric][value] = i\n",
        "\n",
        "    return mappings\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def enforce_causal_discrimination(data, categories, reference_metric, reference_value):\n",
        "    index = categories.index(reference_metric)\n",
        "    augmented_data = list.copy(data)\n",
        "\n",
        "    # Loop through training data and add an entry for each class besides the reference class\n",
        "    for i, row in enumerate(data):\n",
        "        if row[index] != reference_value:\n",
        "            duplicate = list.copy(row)\n",
        "            duplicate[index] = reference_value\n",
        "            augmented_data.append(duplicate)\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm7WH4lggOXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab52bd0d-4314-4663-9f7a-2739f2db32e2"
      },
      "source": [
        "from sklearn import svm\n",
        "# from Preprocessing import preprocess\n",
        "# from Report_Results import report_results\n",
        "import numpy as np\n",
        "# from utils import *\n",
        "\n",
        "\n",
        "def SVM_classification(metrics):\n",
        "\n",
        "    training_data, training_labels, test_data, test_labels, categories, mappings = preprocess(metrics, recalculate=False, causal=False)\n",
        "\n",
        "    np.random.seed(42)\n",
        "    SVR = svm.LinearSVR(C=1.0/float(len(test_data)), max_iter=5000)\n",
        "    SVR.fit(training_data, training_labels)\n",
        "\n",
        "    data = np.concatenate((training_data, test_data))\n",
        "    labels = np.concatenate((training_labels, test_labels))\n",
        "\n",
        "    predictions = SVR.predict(data)\n",
        "    return data, predictions, labels, categories, mappings\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "metrics = [\"sex\", \"age_cat\", 'race', 'c_charge_degree', 'priors_count']\n",
        "\n",
        "data, predictions, labels, categories, mappings = SVM_classification(metrics)\n",
        "race_cases = get_cases_by_metric(data, categories, \"race\", mappings, predictions, labels)\n",
        "\n",
        "report_results(race_cases)\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training data\n",
            "Attempting to enforce demographic parity...\n",
            "--------------------DEMOGRAPHIC PARITY RESULTS--------------------\n",
            "\n",
            "Probability of positive prediction for African-American: 0.6167061611374408\n",
            "Probability of positive prediction for Caucasian: 0.6087357736081206\n",
            "Probability of positive prediction for Hispanic: 0.6127886323268206\n",
            "Probability of positive prediction for Other: 0.5976331360946746\n",
            "\n",
            "Accuracy for African-American: 0.6252962085308057\n",
            "Accuracy for Caucasian: 0.6334973854198708\n",
            "Accuracy for Hispanic: 0.5968028419182948\n",
            "Accuracy for Other: 0.6005917159763313\n",
            "\n",
            "FPR for African-American: 0.4901694915254237\n",
            "FPR for Caucasian: 0.47523838818824976\n",
            "FPR for Hispanic: 0.513595166163142\n",
            "FPR for Other: 0.4975609756097561\n",
            "\n",
            "FNR for African-American: 0.28511309836927934\n",
            "FNR for Caucasian: 0.25776684097200864\n",
            "FNR for Hispanic: 0.24568965517241378\n",
            "FNR for Other: 0.24812030075187969\n",
            "\n",
            "TPR for African-American: 0.7148869016307207\n",
            "TPR for Caucasian: 0.7422331590279914\n",
            "TPR for Hispanic: 0.7543103448275862\n",
            "TPR for Other: 0.7518796992481203\n",
            "\n",
            "TNR for African-American: 0.5098305084745762\n",
            "TNR for Caucasian: 0.5247616118117502\n",
            "TNR for Hispanic: 0.48640483383685795\n",
            "TNR for Other: 0.5024390243902439\n",
            "\n",
            "Threshold for African-American: 0.12\n",
            "Threshold for Caucasian: 0.09\n",
            "Threshold for Hispanic: 0.05\n",
            "Threshold for Other: 0.03\n",
            "\n",
            "Total cost: \n",
            "$-757,300,176\n",
            "Total accuracy: 0.6279803321272845\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce equal opportunity...\n",
            "--------------------EQUAL OPPORTUNITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6347748815165877\n",
            "Accuracy for Caucasian: 0.6268840356813288\n",
            "Accuracy for Hispanic: 0.5950266429840142\n",
            "Accuracy for Other: 0.6005917159763313\n",
            "\n",
            "FPR for African-American: 0.512542372881356\n",
            "FPR for Caucasian: 0.5032297754537065\n",
            "FPR for Hispanic: 0.5166163141993958\n",
            "FPR for Other: 0.4975609756097561\n",
            "\n",
            "FNR for African-American: 0.25092056812204105\n",
            "FNR for Caucasian: 0.2430021531836358\n",
            "FNR for Hispanic: 0.24568965517241378\n",
            "FNR for Other: 0.24812030075187969\n",
            "\n",
            "TPR for African-American: 0.749079431877959\n",
            "TPR for Caucasian: 0.7569978468163642\n",
            "TPR for Hispanic: 0.7543103448275862\n",
            "TPR for Other: 0.7518796992481203\n",
            "\n",
            "TNR for African-American: 0.48745762711864404\n",
            "TNR for Caucasian: 0.4967702245462935\n",
            "TNR for Hispanic: 0.4833836858006042\n",
            "TNR for Other: 0.5024390243902439\n",
            "\n",
            "Threshold for African-American: 0.11\n",
            "Threshold for Caucasian: 0.08\n",
            "Threshold for Hispanic: 0.04\n",
            "Threshold for Other: 0.03\n",
            "\n",
            "Total cost: \n",
            "$-757,870,974\n",
            "Total accuracy: 0.6268670563132016\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce maximum profit...\n",
            "--------------------MAXIMUM PROFIT RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6445497630331753\n",
            "Accuracy for Caucasian: 0.6334973854198708\n",
            "Accuracy for Hispanic: 0.6536412078152753\n",
            "Accuracy for Other: 0.6745562130177515\n",
            "\n",
            "FPR for African-American: 0.6291525423728813\n",
            "FPR for Caucasian: 0.47523838818824976\n",
            "FPR for Hispanic: 0.3474320241691843\n",
            "FPR for Other: 0.1024390243902439\n",
            "\n",
            "FNR for African-American: 0.14308258811152025\n",
            "FNR for Caucasian: 0.25776684097200864\n",
            "FNR for Hispanic: 0.3448275862068966\n",
            "FNR for Other: 0.6691729323308271\n",
            "\n",
            "TPR for African-American: 0.8569174118884797\n",
            "TPR for Caucasian: 0.7422331590279914\n",
            "TPR for Hispanic: 0.6551724137931034\n",
            "TPR for Other: 0.3308270676691729\n",
            "\n",
            "TNR for African-American: 0.3708474576271187\n",
            "TNR for Caucasian: 0.5247616118117502\n",
            "TNR for Hispanic: 0.6525679758308157\n",
            "TNR for Other: 0.8975609756097561\n",
            "\n",
            "Threshold for African-American: 0.08\n",
            "Threshold for Caucasian: 0.09\n",
            "Threshold for Hispanic: 0.09\n",
            "Threshold for Other: 0.68\n",
            "\n",
            "Total cost: \n",
            "$-739,317,978\n",
            "Total accuracy: 0.6392986362371278\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce predictive parity...\n",
            "--------------------PREDICTIVE PARITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6238151658767772\n",
            "Accuracy for Caucasian: 0.6334973854198708\n",
            "Accuracy for Hispanic: 0.6447602131438721\n",
            "Accuracy for Other: 0.6627218934911243\n",
            "\n",
            "PPV for African-American: 0.6109743228983469\n",
            "PPV for Caucasian: 0.6096513390601314\n",
            "PPV for Hispanic: 0.6095890410958904\n",
            "PPV for Other: 0.6043956043956044\n",
            "\n",
            "FPR for African-American: 0.7498305084745762\n",
            "FPR for Caucasian: 0.47523838818824976\n",
            "FPR for Hispanic: 0.17220543806646527\n",
            "FPR for Other: 0.17560975609756097\n",
            "\n",
            "FNR for African-American: 0.08627038400841662\n",
            "FNR for Caucasian: 0.25776684097200864\n",
            "FNR for Hispanic: 0.6163793103448276\n",
            "FNR for Other: 0.5864661654135338\n",
            "\n",
            "TPR for African-American: 0.9137296159915834\n",
            "TPR for Caucasian: 0.7422331590279914\n",
            "TPR for Hispanic: 0.3836206896551724\n",
            "TPR for Other: 0.4135338345864662\n",
            "\n",
            "TNR for African-American: 0.2501694915254238\n",
            "TNR for Caucasian: 0.5247616118117502\n",
            "TNR for Hispanic: 0.8277945619335347\n",
            "TNR for Other: 0.8243902439024391\n",
            "\n",
            "Threshold for African-American: 0.04\n",
            "Threshold for Caucasian: 0.09\n",
            "Threshold for Hispanic: 0.36\n",
            "Threshold for Other: 0.38\n",
            "\n",
            "Total cost: \n",
            "$-749,328,894\n",
            "Total accuracy: 0.6319695704610817\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce single threshold...\n",
            "--------------------SINGLE THRESHOLD RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6365521327014217\n",
            "Accuracy for Caucasian: 0.6334973854198708\n",
            "Accuracy for Hispanic: 0.6536412078152753\n",
            "Accuracy for Other: 0.650887573964497\n",
            "\n",
            "FPR for African-American: 0.6250847457627119\n",
            "FPR for Caucasian: 0.47523838818824976\n",
            "FPR for Hispanic: 0.3474320241691843\n",
            "FPR for Other: 0.2975609756097561\n",
            "\n",
            "FNR for African-American: 0.1604418726985797\n",
            "FNR for Caucasian: 0.25776684097200864\n",
            "FNR for Hispanic: 0.3448275862068966\n",
            "FNR for Other: 0.42857142857142855\n",
            "\n",
            "TPR for African-American: 0.8395581273014203\n",
            "TPR for Caucasian: 0.7422331590279914\n",
            "TPR for Hispanic: 0.6551724137931034\n",
            "TPR for Other: 0.5714285714285714\n",
            "\n",
            "TNR for African-American: 0.3749152542372881\n",
            "TNR for Caucasian: 0.5247616118117502\n",
            "TNR for Hispanic: 0.6525679758308157\n",
            "TNR for Other: 0.7024390243902439\n",
            "\n",
            "Threshold for African-American: 0.09\n",
            "Threshold for Caucasian: 0.09\n",
            "Threshold for Hispanic: 0.09\n",
            "Threshold for Other: 0.09\n",
            "\n",
            "Total cost: \n",
            "$-743,987,808\n",
            "Total accuracy: 0.6360515817793858\n",
            "-----------------------------------------------------------------\n",
            "Postprocessing took approximately: 0:00:30.041192 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u59dDPWWtL4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7077652d-e8ae-4770-dc2c-1570158bae41"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(4940)\n",
        "import tensorflow #import set_random_seed\n",
        "# set_random_seed(80)\n",
        "\n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "# from Preprocessing import preprocess\n",
        "# from Report_Results import report_results\n",
        "# from utils import *\n",
        "\n",
        "\n",
        "def neural_network_classification(metrics):\n",
        "\n",
        "    training_data, training_labels, test_data, test_labels, categories, mappings = preprocess(metrics)\n",
        "\n",
        "    activation = \"relu\"\n",
        "    model = Sequential()\n",
        "    model.add(Dense(len(metrics)*2, activation=activation, kernel_regularizer=regularizers.l2(0.1), input_shape = (len(metrics), )))\n",
        "    model.add(Dense(30, activation=activation, kernel_regularizer=regularizers.l2(0.1)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss=\"binary_crossentropy\")\n",
        "    model.fit(training_data, training_labels, epochs=30, batch_size=300, validation_data=(test_data, test_labels), verbose=0)\n",
        "\n",
        "    data = np.concatenate((training_data, test_data))\n",
        "    labels = np.concatenate((training_labels, test_labels))\n",
        "\n",
        "    predictions = model.predict(data)\n",
        "    predictions = np.squeeze(predictions, axis=1)\n",
        "\n",
        "    return data, predictions, labels, categories, mappings\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "\n",
        "metrics = [\"sex\", \"age_cat\", \"race\", 'c_charge_degree', 'priors_count']\n",
        "\n",
        "# Changing the int value sets the number of models to create before choosing the \"best\" one\n",
        "data, predictions, labels, categories, mappings = neural_network_classification(metrics)\n",
        "race_cases = get_cases_by_metric(data, categories, \"race\", mappings, predictions, labels)\n",
        "\n",
        "report_results(race_cases)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training data\n",
            "Attempting to enforce demographic parity...\n",
            "--------------------DEMOGRAPHIC PARITY RESULTS--------------------\n",
            "\n",
            "Probability of positive prediction for African-American: 0.3728813559322034\n",
            "Probability of positive prediction for Caucasian: 0.3646308113035551\n",
            "Probability of positive prediction for Hispanic: 0.3805309734513274\n",
            "Probability of positive prediction for Other: 0.3611940298507463\n",
            "\n",
            "Accuracy for African-American: 0.552482902170681\n",
            "Accuracy for Caucasian: 0.5925250683682771\n",
            "Accuracy for Hispanic: 0.6300884955752213\n",
            "Accuracy for Other: 0.6537313432835821\n",
            "\n",
            "FPR for African-American: 0.29343365253077974\n",
            "FPR for Caucasian: 0.2964169381107492\n",
            "FPR for Hispanic: 0.2882882882882883\n",
            "FPR for Other: 0.25742574257425743\n",
            "\n",
            "FNR for African-American: 0.5660178853235139\n",
            "FNR for Caucasian: 0.5486542443064182\n",
            "FNR for Hispanic: 0.4870689655172414\n",
            "FNR for Other: 0.48120300751879697\n",
            "\n",
            "TPR for African-American: 0.43398211467648606\n",
            "TPR for Caucasian: 0.4513457556935818\n",
            "TPR for Hispanic: 0.5129310344827587\n",
            "TPR for Other: 0.518796992481203\n",
            "\n",
            "TNR for African-American: 0.7065663474692203\n",
            "TNR for Caucasian: 0.7035830618892508\n",
            "TNR for Hispanic: 0.7117117117117118\n",
            "TNR for Other: 0.7425742574257426\n",
            "\n",
            "Threshold for African-American: 0.55\n",
            "Threshold for Caucasian: 0.52\n",
            "Threshold for Hispanic: 0.44\n",
            "Threshold for Other: 0.45\n",
            "\n",
            "Total cost: \n",
            "$-498,653,038\n",
            "Total accuracy: 0.5781322595632646\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce equal opportunity...\n",
            "--------------------EQUAL OPPORTUNITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.5590246803449301\n",
            "Accuracy for Caucasian: 0.6048313582497721\n",
            "Accuracy for Hispanic: 0.631858407079646\n",
            "Accuracy for Other: 0.6388059701492538\n",
            "\n",
            "FPR for African-American: 0.4103967168262654\n",
            "FPR for Caucasian: 0.34527687296416937\n",
            "FPR for Hispanic: 0.3033033033033033\n",
            "FPR for Other: 0.29207920792079206\n",
            "\n",
            "FNR for African-American: 0.46449237243556024\n",
            "FNR for Caucasian: 0.458592132505176\n",
            "FNR for Hispanic: 0.46120689655172414\n",
            "FNR for Other: 0.46616541353383456\n",
            "\n",
            "TPR for African-American: 0.5355076275644397\n",
            "TPR for Caucasian: 0.541407867494824\n",
            "TPR for Hispanic: 0.5387931034482758\n",
            "TPR for Other: 0.5338345864661654\n",
            "\n",
            "TNR for African-American: 0.5896032831737346\n",
            "TNR for Caucasian: 0.6547231270358307\n",
            "TNR for Hispanic: 0.6966966966966968\n",
            "TNR for Other: 0.7079207920792079\n",
            "\n",
            "Threshold for African-American: 0.53\n",
            "Threshold for Caucasian: 0.48\n",
            "Threshold for Hispanic: 0.41\n",
            "Threshold for Other: 0.39\n",
            "\n",
            "Total cost: \n",
            "$-490,042,738\n",
            "Total accuracy: 0.5851014402973517\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce maximum profit...\n",
            "--------------------MAXIMUM PROFIT RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.63990484686292\n",
            "Accuracy for Caucasian: 0.618049225159526\n",
            "Accuracy for Hispanic: 0.631858407079646\n",
            "Accuracy for Other: 0.6716417910447762\n",
            "\n",
            "FPR for African-American: 0.5560875512995896\n",
            "FPR for Caucasian: 0.3745928338762215\n",
            "FPR for Hispanic: 0.3033033033033033\n",
            "FPR for Other: 0.1188118811881188\n",
            "\n",
            "FNR for African-American: 0.20936349289847447\n",
            "FNR for Caucasian: 0.391304347826087\n",
            "FNR for Hispanic: 0.46120689655172414\n",
            "FNR for Other: 0.6466165413533834\n",
            "\n",
            "TPR for African-American: 0.7906365071015256\n",
            "TPR for Caucasian: 0.6086956521739131\n",
            "TPR for Hispanic: 0.5387931034482758\n",
            "TPR for Other: 0.3533834586466166\n",
            "\n",
            "TNR for African-American: 0.44391244870041036\n",
            "TNR for Caucasian: 0.6254071661237786\n",
            "TNR for Hispanic: 0.6966966966966968\n",
            "TNR for Other: 0.8811881188118812\n",
            "\n",
            "Threshold for African-American: 0.43\n",
            "Threshold for Caucasian: 0.42\n",
            "Threshold for Hispanic: 0.41\n",
            "Threshold for Other: 0.56\n",
            "\n",
            "Total cost: \n",
            "$-443,714,230\n",
            "Total accuracy: 0.6334210933870218\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce predictive parity...\n",
            "--------------------PREDICTIVE PARITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6131430270591733\n",
            "Accuracy for Caucasian: 0.6048313582497721\n",
            "Accuracy for Hispanic: 0.6212389380530974\n",
            "Accuracy for Other: 0.6537313432835821\n",
            "\n",
            "PPV for African-American: 0.6029512697323267\n",
            "PPV for Caucasian: 0.598019801980198\n",
            "PPV for Hispanic: 0.6046511627906976\n",
            "PPV for Other: 0.6075949367088608\n",
            "\n",
            "FPR for African-American: 0.7913816689466484\n",
            "FPR for Caucasian: 0.16530944625407165\n",
            "FPR for Hispanic: 0.1021021021021021\n",
            "FPR for Other: 0.15346534653465346\n",
            "\n",
            "FNR for African-American: 0.07574960547080484\n",
            "FNR for Caucasian: 0.6873706004140787\n",
            "FNR for Hispanic: 0.7758620689655172\n",
            "FNR for Other: 0.6390977443609023\n",
            "\n",
            "TPR for African-American: 0.9242503945291951\n",
            "TPR for Caucasian: 0.3126293995859213\n",
            "TPR for Hispanic: 0.22413793103448276\n",
            "TPR for Other: 0.3609022556390977\n",
            "\n",
            "TNR for African-American: 0.2086183310533516\n",
            "TNR for Caucasian: 0.8346905537459284\n",
            "TNR for Hispanic: 0.8978978978978979\n",
            "TNR for Other: 0.8465346534653465\n",
            "\n",
            "Threshold for African-American: 0.41\n",
            "Threshold for Caucasian: 0.58\n",
            "Threshold for Hispanic: 0.58\n",
            "Threshold for Other: 0.53\n",
            "\n",
            "Total cost: \n",
            "$-462,104,074\n",
            "Total accuracy: 0.6131330339166796\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce single threshold...\n",
            "--------------------SINGLE THRESHOLD RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.63990484686292\n",
            "Accuracy for Caucasian: 0.6148587055606198\n",
            "Accuracy for Hispanic: 0.631858407079646\n",
            "Accuracy for Other: 0.6507462686567164\n",
            "\n",
            "FPR for African-American: 0.5560875512995896\n",
            "FPR for Caucasian: 0.36156351791530944\n",
            "FPR for Hispanic: 0.2912912912912913\n",
            "FPR for Other: 0.2623762376237624\n",
            "\n",
            "FNR for African-American: 0.20936349289847447\n",
            "FNR for Caucasian: 0.41511387163561075\n",
            "FNR for Hispanic: 0.47844827586206895\n",
            "FNR for Other: 0.48120300751879697\n",
            "\n",
            "TPR for African-American: 0.7906365071015256\n",
            "TPR for Caucasian: 0.5848861283643892\n",
            "TPR for Hispanic: 0.521551724137931\n",
            "TPR for Other: 0.518796992481203\n",
            "\n",
            "TNR for African-American: 0.44391244870041036\n",
            "TNR for Caucasian: 0.6384364820846906\n",
            "TNR for Hispanic: 0.7087087087087087\n",
            "TNR for Other: 0.7376237623762376\n",
            "\n",
            "Threshold for African-American: 0.43\n",
            "Threshold for Caucasian: 0.43\n",
            "Threshold for Hispanic: 0.43\n",
            "Threshold for Other: 0.43\n",
            "\n",
            "Total cost: \n",
            "$-445,623,976\n",
            "Total accuracy: 0.6312529038253059\n",
            "-----------------------------------------------------------------\n",
            "Postprocessing took approximately: 0:00:38.598437 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz1scTpu5gGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e544f20d-54d6-4323-ee11-ac43417d2c18"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import numpy as np\n",
        "# from Preprocessing import preprocess\n",
        "# from Report_Results import report_results\n",
        "# from utils import *\n",
        "\n",
        "\n",
        "def naive_bayes_classification(metrics):\n",
        "    training_data, training_labels, test_data, test_labels, categories, mappings = preprocess(metrics)\n",
        "\n",
        "    NBC = MultinomialNB()\n",
        "    NBC.fit(training_data, training_labels)\n",
        "\n",
        "    data = np.concatenate((training_data, test_data))\n",
        "    labels = np.concatenate((training_labels, test_labels))\n",
        "\n",
        "    class_predictions = NBC.predict_proba(data)\n",
        "    predictions = []\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        predictions.append(class_predictions[i][1])\n",
        "\n",
        "    return data, predictions, labels, categories, mappings\n",
        "\n",
        "\n",
        "metrics = [\"race\", \"sex\", \"age\", 'c_charge_degree', 'priors_count', 'c_charge_desc']\n",
        "data, predictions, labels, categories, mappings = naive_bayes_classification(metrics)\n",
        "race_cases = get_cases_by_metric(data, categories, \"race\", mappings, predictions, labels)\n",
        "\n",
        "report_results(race_cases)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded training data\n",
            "Attempting to enforce demographic parity...\n",
            "--------------------DEMOGRAPHIC PARITY RESULTS--------------------\n",
            "\n",
            "Probability of positive prediction for African-American: 0.591824644549763\n",
            "Probability of positive prediction for Caucasian: 0.5733620424484774\n",
            "Probability of positive prediction for Hispanic: 0.5772646536412078\n",
            "Probability of positive prediction for Other: 0.5857988165680473\n",
            "\n",
            "Accuracy for African-American: 0.6170023696682464\n",
            "Accuracy for Caucasian: 0.6291910181482621\n",
            "Accuracy for Hispanic: 0.6252220248667851\n",
            "Accuracy for Other: 0.6420118343195266\n",
            "\n",
            "FPR for African-American: 0.4711864406779661\n",
            "FPR for Caucasian: 0.4441710243002153\n",
            "FPR for Hispanic: 0.459214501510574\n",
            "FPR for Other: 0.45365853658536587\n",
            "\n",
            "FNR for African-American: 0.3145712782745923\n",
            "FNR for Caucasian: 0.29744693940326056\n",
            "FNR for Hispanic: 0.2543103448275862\n",
            "FNR for Other: 0.21052631578947367\n",
            "\n",
            "TPR for African-American: 0.6854287217254077\n",
            "TPR for Caucasian: 0.7025530605967394\n",
            "TPR for Hispanic: 0.7456896551724138\n",
            "TPR for Other: 0.7894736842105263\n",
            "\n",
            "TNR for African-American: 0.5288135593220339\n",
            "TNR for Caucasian: 0.5558289756997847\n",
            "TNR for Hispanic: 0.540785498489426\n",
            "TNR for Other: 0.5463414634146342\n",
            "\n",
            "Threshold for African-American: 0.36\n",
            "Threshold for Caucasian: 0.16\n",
            "Threshold for Hispanic: 0.04\n",
            "Threshold for Other: 0.03\n",
            "\n",
            "Total cost: \n",
            "$-762,416,820\n",
            "Total accuracy: 0.6255682345301048\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce equal opportunity...\n",
            "--------------------EQUAL OPPORTUNITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6220379146919431\n",
            "Accuracy for Caucasian: 0.6291910181482621\n",
            "Accuracy for Hispanic: 0.6483126110124334\n",
            "Accuracy for Other: 0.6390532544378699\n",
            "\n",
            "FPR for African-American: 0.4935593220338983\n",
            "FPR for Caucasian: 0.4441710243002153\n",
            "FPR for Hispanic: 0.39274924471299094\n",
            "FPR for Other: 0.40487804878048783\n",
            "\n",
            "FNR for African-American: 0.28826933193056287\n",
            "FNR for Caucasian: 0.29744693940326056\n",
            "FNR for Hispanic: 0.29310344827586204\n",
            "FNR for Other: 0.2932330827067669\n",
            "\n",
            "TPR for African-American: 0.7117306680694371\n",
            "TPR for Caucasian: 0.7025530605967394\n",
            "TPR for Hispanic: 0.7068965517241379\n",
            "TPR for Other: 0.7067669172932332\n",
            "\n",
            "TNR for African-American: 0.5064406779661017\n",
            "TNR for Caucasian: 0.5558289756997847\n",
            "TNR for Hispanic: 0.607250755287009\n",
            "TNR for Other: 0.5951219512195122\n",
            "\n",
            "Threshold for African-American: 0.31\n",
            "Threshold for Caucasian: 0.16\n",
            "Threshold for Hispanic: 0.09\n",
            "Threshold for Other: 0.07\n",
            "\n",
            "Total cost: \n",
            "$-758,282,364\n",
            "Total accuracy: 0.6282586510808053\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce maximum profit...\n",
            "--------------------MAXIMUM PROFIT RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6273696682464455\n",
            "Accuracy for Caucasian: 0.6291910181482621\n",
            "Accuracy for Hispanic: 0.6820603907637656\n",
            "Accuracy for Other: 0.6923076923076923\n",
            "\n",
            "FPR for African-American: 0.5410169491525424\n",
            "FPR for Caucasian: 0.4441710243002153\n",
            "FPR for Hispanic: 0.1933534743202417\n",
            "FPR for Other: 0.18536585365853658\n",
            "\n",
            "FNR for African-American: 0.24197790636507102\n",
            "FNR for Caucasian: 0.29744693940326056\n",
            "FNR for Hispanic: 0.4956896551724138\n",
            "FNR for Other: 0.49624060150375937\n",
            "\n",
            "TPR for African-American: 0.758022093634929\n",
            "TPR for Caucasian: 0.7025530605967394\n",
            "TPR for Hispanic: 0.5043103448275862\n",
            "TPR for Other: 0.5037593984962406\n",
            "\n",
            "TNR for African-American: 0.4589830508474576\n",
            "TNR for Caucasian: 0.5558289756997847\n",
            "TNR for Hispanic: 0.8066465256797584\n",
            "TNR for Other: 0.8146341463414635\n",
            "\n",
            "Threshold for African-American: 0.21\n",
            "Threshold for Caucasian: 0.16\n",
            "Threshold for Hispanic: 0.5\n",
            "Threshold for Other: 0.48\n",
            "\n",
            "Total cost: \n",
            "$-750,831,084\n",
            "Total accuracy: 0.6333611652286854\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce predictive parity...\n",
            "--------------------PREDICTIVE PARITY RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6273696682464455\n",
            "Accuracy for Caucasian: 0.6267302368501999\n",
            "Accuracy for Hispanic: 0.6802841918294849\n",
            "Accuracy for Other: 0.6923076923076923\n",
            "\n",
            "PPV for African-American: 0.6435908887896382\n",
            "PPV for Caucasian: 0.6357943309162821\n",
            "PPV for Hispanic: 0.6444444444444445\n",
            "PPV for Other: 0.638095238095238\n",
            "\n",
            "FPR for African-American: 0.5410169491525424\n",
            "FPR for Caucasian: 0.3398954167948324\n",
            "FPR for Hispanic: 0.1933534743202417\n",
            "FPR for Other: 0.18536585365853658\n",
            "\n",
            "FNR for African-American: 0.24197790636507102\n",
            "FNR for Caucasian: 0.40664410950476776\n",
            "FNR for Hispanic: 0.5\n",
            "FNR for Other: 0.49624060150375937\n",
            "\n",
            "TPR for African-American: 0.758022093634929\n",
            "TPR for Caucasian: 0.5933558904952323\n",
            "TPR for Hispanic: 0.5\n",
            "TPR for Other: 0.5037593984962406\n",
            "\n",
            "TNR for African-American: 0.4589830508474576\n",
            "TNR for Caucasian: 0.6601045832051676\n",
            "TNR for Hispanic: 0.8066465256797584\n",
            "TNR for Other: 0.8146341463414635\n",
            "\n",
            "Threshold for African-American: 0.21\n",
            "Threshold for Caucasian: 0.39\n",
            "Threshold for Hispanic: 0.52\n",
            "Threshold for Other: 0.48\n",
            "\n",
            "Total cost: \n",
            "$-756,330,912\n",
            "Total accuracy: 0.6317840244920679\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Attempting to enforce single threshold...\n",
            "--------------------SINGLE THRESHOLD RESULTS--------------------\n",
            "\n",
            "Accuracy for African-American: 0.6273696682464455\n",
            "Accuracy for Caucasian: 0.6285758228237466\n",
            "Accuracy for Hispanic: 0.6571936056838366\n",
            "Accuracy for Other: 0.6715976331360947\n",
            "\n",
            "FPR for African-American: 0.5410169491525424\n",
            "FPR for Caucasian: 0.41679483235927406\n",
            "FPR for Hispanic: 0.3021148036253776\n",
            "FPR for Other: 0.2682926829268293\n",
            "\n",
            "FNR for African-American: 0.24197790636507102\n",
            "FNR for Caucasian: 0.32605352199323284\n",
            "FNR for Hispanic: 0.40086206896551724\n",
            "FNR for Other: 0.42105263157894735\n",
            "\n",
            "TPR for African-American: 0.758022093634929\n",
            "TPR for Caucasian: 0.6739464780067672\n",
            "TPR for Hispanic: 0.5991379310344828\n",
            "TPR for Other: 0.5789473684210527\n",
            "\n",
            "TNR for African-American: 0.4589830508474576\n",
            "TNR for Caucasian: 0.5832051676407259\n",
            "TNR for Hispanic: 0.6978851963746224\n",
            "TNR for Other: 0.7317073170731707\n",
            "\n",
            "Threshold for African-American: 0.21\n",
            "Threshold for Caucasian: 0.21\n",
            "Threshold for Hispanic: 0.21\n",
            "Threshold for Other: 0.21\n",
            "\n",
            "Total cost: \n",
            "$-754,714,674\n",
            "Total accuracy: 0.6310418406160127\n",
            "-----------------------------------------------------------------\n",
            "Postprocessing took approximately: 0:02:10.973663 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECQnKzEw5qTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}